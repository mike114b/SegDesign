import shutil
import subprocess
import os
import logging
from typing import Dict, Optional, List
import shlex
import argparse
from pathlib import Path
import yaml
import sys
import threading
from Bio.PDB import MMCIFParser, PDBIO
from numpy.ma.core import identity


# é…ç½®é¡¹ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
CONFIG = {
    "MODULES":{
        'hmmer': {"path":'./Segdesign/hmmer/hmmer.py'},
        'rfdiffusion': {"path":'./Segdesign/rfdiffusion/rf_diffusion.py'},
        'rfdiffusion_report': {"path":'./Segdesign/rfdiffusion/rf_diffusion_report.py'},
        'mpnn': {"path":'./Segdesign/mpnn/mpnn.py'},
        'mmseqs': {"path":'./Segdesign/mmseqs/mmseqs.py'},
        'mpnn_report': {"path":'./Segdesign/mpnn/mpnn_report.py'},
        'esmfold': {"path":'./Segdesign/esmfold/esmfold.py'},
        'esmfold_report': {"path":'./Segdesign/esmfold/esmfold_report.py'},
        'alphafold2': {"path":'./Segdesign/alphafold2/af2.py'},
        'alphafold2_report': {"path":'./Segdesign/alphafold2/af2_report.py'},
        'dssp': {"path":'./dssp/dssp.py'},
        'cluster_analysis':{"path":'./Segdesign/mpnn/cluster_analysis.py'},
    },
    "CONFIG_PATH": {
        "MAIN": "./config/config.yaml",
        "SETTING": "./config/setting.yaml"
    }
}


def setup_logger(log_path, console_output=True):
    # 1. å¤„ç†æ—¥å¿—ç›®å½•ï¼ˆåˆ›å»ºä¸å­˜åœ¨çš„ç›®å½•ï¼‰
    log_dir = os.path.dirname(log_path)
    if log_dir and not os.path.exists(log_dir):
        os.makedirs(log_dir, exist_ok=True)

    # 2. åˆ›å»º/è·å–å‘½åæ—¥å¿—å™¨ï¼ˆ__name__ï¼‰
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)  # è®¾ç½®æ—¥å¿—å™¨çº§åˆ«ï¼ˆå¿…é¡»â‰¥è¾“å‡ºæ—¥å¿—çš„çº§åˆ«ï¼‰
    logger.propagate = False  # ç¦ç”¨ä¼ æ’­ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰

    # 3. æ¸…ç©ºå·²æœ‰Handlerï¼ˆé¿å…å¤šæ¬¡è°ƒç”¨é‡å¤è¾“å‡ºï¼‰
    if logger.handlers:
        logger.handlers.clear()

    # 4. ç»™å‘½åæ—¥å¿—å™¨ç»‘å®šæ–‡ä»¶Handlerï¼ˆæ ¸å¿ƒï¼šè®©æ—¥å¿—æœ‰è¾“å‡ºç›®æ ‡ï¼‰
    file_handler = logging.FileHandler(
        log_path,
        mode='w',  # è¦†ç›–æ¨¡å¼ï¼Œæ¸…ç©ºæ—§å†…å®¹
        encoding='utf-8'  # é¿å…ä¸­æ–‡ä¹±ç 
    )
    # é…ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # å¯é€‰ï¼šæ·»åŠ æ§åˆ¶å°Handlerï¼ˆæ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°+æ–‡ä»¶ï¼‰
    if console_output:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)


    return logger



def validate_environment(env_name: str) -> bool:
    """éªŒè¯Condaç¯å¢ƒæ˜¯å¦å­˜åœ¨"""
    conda_info_cmd = [
        f"{CONFIG['MINICONDA_PATH']}/bin/conda",
        "info",
        "--envs"
    ]

    try:
        result = subprocess.run(
            conda_info_cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
            timeout=30
        )
        # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦åœ¨è¾“å‡ºä¸­ï¼ˆæ”¯æŒå®Œæ•´åç§°åŒ¹é…ï¼‰
        return any(f"*{env_name}" in line or f"  {env_name} " in line for line in result.stdout.splitlines())
    except subprocess.TimeoutExpired:
        logger.warning(f"éªŒè¯ç¯å¢ƒ {env_name} è¶…æ—¶")
        logger.warning(f"Environment {env_name} validation timeout")
        return False
    except subprocess.CalledProcessError as e:
        logger.error(f"éªŒè¯ç¯å¢ƒå¤±è´¥: {e.stderr}")
        logger.error(f"Environment validation failed: {e.stderr}")
        return False


def validate_module(module_name: str) -> str:
    """éªŒè¯æ¨¡å—æ˜¯å¦å­˜åœ¨å¹¶è¿”å›å®Œæ•´è·¯å¾„"""
    if module_name not in CONFIG['MODULES']:
        raise ModuleRunnerError(f"æ¨¡å— {module_name} æœªåœ¨é…ç½®ä¸­å®šä¹‰ï¼Œå¯ç”¨æ¨¡å—: {list(CONFIG['MODULES'].keys())}")
        raise ModuleRunnerError(f"Module {module_name} is not defined in configuration, available modules: {list(CONFIG['MODULES'].keys())}")

    module_path = os.path.abspath(CONFIG['MODULES'][module_name]['path'])
    if not os.path.exists(module_path):
        raise ModuleRunnerError(f"æ¨¡å—æ–‡ä»¶ä¸å­˜åœ¨: {module_path}")
        raise ModuleRunnerError(f"Module file does not exist: {module_path}")

    if not os.access(module_path, os.R_OK):
        raise ModuleRunnerError(f"æ¨¡å—æ–‡ä»¶æ— è¯»å–æƒé™: {module_path}")
        raise ModuleRunnerError(f"Module file has no read permission: {module_path}")

    return module_path


def build_command(module_name: str, module_path: str, anaconda_path, env_name: str, custom_args: List[str], module_log_config='') -> str:
    """æ„å»ºå®‰å…¨çš„æ‰§è¡Œå‘½ä»¤"""


    # åˆå¹¶é»˜è®¤å‚æ•°å’Œè‡ªå®šä¹‰å‚æ•°ï¼ˆè‡ªå®šä¹‰å‚æ•°ä¼˜å…ˆçº§æ›´é«˜ï¼‰
    #default_args = MODULE_CONFIG[module_name]["default_args"]
    #final_args = default_args + custom_args

    # å®‰å…¨è½¬ä¹‰æ‰€æœ‰å‚æ•°ï¼Œé˜²æ­¢å‘½ä»¤æ³¨å…¥
    escaped_args = [shlex.quote(arg) for arg in custom_args]
    args_str = " ".join(escaped_args)

    # æ„å»ºå‘½ä»¤ï¼ˆä½¿ç”¨set -eç¡®ä¿ä»»ä¸€å‘½ä»¤å¤±è´¥å³é€€å‡ºï¼‰
    if anaconda_path is not None:
        anaconda_path = os.path.expanduser(anaconda_path)
        command = f"""
            #!/bin/bash
            set -euo pipefail
            PS1="${{PS1:-}}"
            # Load conda environment
            if [ -f "{shlex.quote(anaconda_path)}/etc/profile.d/conda.sh" ]; then
                source "{shlex.quote(anaconda_path)}/etc/profile.d/conda.sh"
            elif [ -f "{shlex.quote(anaconda_path)}/bin/activate" ]; then
                source "{shlex.quote(anaconda_path)}/bin/activate"
            else
                echo "Conda activation script not found" >&2
                exit 1
            fi

            # Activate environment and run module
            conda activate {shlex.quote(env_name)}
            python -u {shlex.quote(module_path)} {args_str} {module_log_config}
            """
    else:
        command = f"""
            # Activate environment and run module
            conda run -n {shlex.quote(env_name)} python -u {shlex.quote(module_path)} {args_str} {module_log_config}
            """

    return command

def run_command(command):
    # åˆ›å»ºå­è¿›ç¨‹ï¼Œæ•è·æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯
    logger.info('*'*10)
    logger.info(f"Now starting to execute the command:\n{command}")
    logger.info('*'*10)
    process = subprocess.Popen(
            command,
            shell=True,
            executable="/bin/bash",
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',  # æ˜¾å¼æŒ‡å®šç¼–ç ï¼Œè§£å†³å­è¿›ç¨‹è¾“å‡ºä¸­æ–‡ä¹±ç 
            errors='ignore'  # å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦ï¼ˆé¿å…å´©æºƒ
        )

    # å®æ—¶æ‰“å°è¾“å‡ºçš„å‡½æ•°
    def print_output():
        for line in iter(process.stdout.readline, ''):
            # ç§»é™¤è¡Œå°¾æ¢è¡Œç¬¦åæ‰“å°
            #print(line, end='')
            logger.info(line)
            sys.stdout.flush()  # ç¡®ä¿ç«‹å³æ˜¾ç¤º
        process.stdout.close()

    # å¯åŠ¨è¾“å‡ºæ‰“å°çº¿ç¨‹
    output_thread = threading.Thread(target=print_output)
    output_thread.daemon = True  # ä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸçº¿ç¨‹
    output_thread.start()
    # ç­‰å¾…è¿›ç¨‹ç»“æŸ
    process.wait()

    # æ£€æŸ¥é€€å‡ºçŠ¶æ€
    if process.returncode == 0:
        # åœºæ™¯1ï¼šé€€å‡ºç 0ï¼Œå®Œå…¨æ­£å¸¸æ‰§è¡Œï¼Œæ— é¢å¤–æ“ä½œï¼Œæ­£å¸¸è¿”å›
        logger.info("\n=== å‘½ä»¤æ‰§è¡ŒæˆåŠŸ ===")
        logger.info("\n=== Command executed successfully ===")
    elif process.returncode == 100:
        # åœºæ™¯2ï¼šé€€å‡ºç 100ï¼Œçº¦å®šæ­£å¸¸ç»ˆæ­¢ï¼ˆæ— æœ‰æ•ˆç»“æœï¼‰ï¼Œä¸æŠ›å¼‚å¸¸ï¼Œæç¤ºä¿¡æ¯
        #print("\n=== å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œæ­£å¸¸ç»ˆæ­¢===")
        logger.info(f"é€€å‡ºç ï¼š{process.returncode}")
        logger.info(f"Exit code: {process.returncode}")
        sys.exit(0)
    elif process.returncode == 101:
        logger.info(f"é€€å‡ºç ï¼š{process.returncode}")
        logger.info(f"Exit code: {process.returncode}")
        sys.exit(0)
    elif process.returncode == 102:
        logger.info(f"é€€å‡ºç ï¼š{process.returncode}")
        logger.info(f"Exit code: {process.returncode}")
        sys.exit(0)
    else:
        # åœºæ™¯3ï¼šå…¶ä»–é0/é100é€€å‡ºç ï¼ŒçœŸæ­£çš„æ‰§è¡Œå¤±è´¥ï¼ŒæŠ›å‡ºåŸæœ‰å¼‚å¸¸
        raise RuntimeError(f"Command execution failedï¼Œexit code: {process.returncode}")
    return


def run_module(
        module_name: str,
        anaconda_path,
        params,
        module_log_config='',
        retry_count: int = 0
) :
    """
    åœ¨æŒ‡å®šCondaç¯å¢ƒä¸­è¿è¡Œæ¨¡å—ï¼ˆæ”¯æŒé‡è¯•ï¼‰

    Args:
        module_name: æ¨¡å—åç§°
        args: æ¨¡å—çš„å‘½ä»¤è¡Œå‚æ•°
        retry_count: å½“å‰é‡è¯•æ¬¡æ•°

    Returns:
        é€€å‡ºä»£ç ï¼ˆ0è¡¨ç¤ºæˆåŠŸï¼‰

    Raises:
        ModuleRunnerError: æ¨¡å—éªŒè¯æˆ–è¿è¡Œå¤±è´¥æ—¶æŠ›å‡º
    """
    # éªŒè¯æ¨¡å—
    try:
        module_path = validate_module(module_name)
    except ModuleRunnerError as e:
        logger.error(f"æ¨¡å—éªŒè¯å¤±è´¥: {e}")
        logger.error(f"Module validation failed: {e}")
        raise

    # è·å–ç¯å¢ƒåç§°
    env_name = params['env_name']
    logger.info(f"ğŸš€ å¯åŠ¨æ¨¡å—: {module_name} (ç¯å¢ƒ: {env_name}, è·¯å¾„: {module_path})")
    logger.info(f"ğŸš€ Starting module: {module_name} (Environment: {env_name}, Path: {module_path})")

    args = [elem for k, v in params['args'].items() for elem in (f'--{k}', str(v))]
    # æ„å»ºå‘½ä»¤
    command = build_command(
        module_name=module_name,
        module_path=module_path,
        anaconda_path=anaconda_path,
        env_name=env_name,
        custom_args=list(args),
        module_log_config=module_log_config,
    )

    run_command(command)
    return



def run_module_old(
        module_name: str,
        anaconda_path,
        params,
        retry_count: int = 0
) -> int:
    """
    åœ¨æŒ‡å®šCondaç¯å¢ƒä¸­è¿è¡Œæ¨¡å—ï¼ˆæ”¯æŒé‡è¯•ï¼‰

    Args:
        module_name: æ¨¡å—åç§°
        args: æ¨¡å—çš„å‘½ä»¤è¡Œå‚æ•°
        retry_count: å½“å‰é‡è¯•æ¬¡æ•°

    Returns:
        é€€å‡ºä»£ç ï¼ˆ0è¡¨ç¤ºæˆåŠŸï¼‰

    Raises:
        ModuleRunnerError: æ¨¡å—éªŒè¯æˆ–è¿è¡Œå¤±è´¥æ—¶æŠ›å‡º
    """
    # éªŒè¯æ¨¡å—
    try:
        module_path = validate_module(module_name)
    except ModuleRunnerError as e:
        logger.error(f"æ¨¡å—éªŒè¯å¤±è´¥: {e}")
        logger.error(f"Module validation failed: {e}")
        raise

    # è·å–ç¯å¢ƒåç§°
    env_name = params['env_name']
    logger.info(f"ğŸš€ å¯åŠ¨æ¨¡å—: {module_name} (ç¯å¢ƒ: {env_name}, è·¯å¾„: {module_path})")
    logger.info(f"ğŸš€ Starting module: {module_name} (Environment: {env_name}, Path: {module_path})")

    args = [elem for k, v in params['args'].items() for elem in (f'--{k}', str(v))]
    # æ„å»ºå‘½ä»¤
    command = build_command(
        module_name=module_name,
        module_path=module_path,
        anaconda_path=os.path.expanduser(anaconda_path),
        env_name=env_name,
        custom_args=list(args)
    )

    try:
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            command,
            shell=True,
            executable="/bin/bash",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
            timeout=CONFIG["COMMAND_TIMEOUT"]
        )

        # è®°å½•è¾“å‡º
        logger.info(f"=== æ¨¡å— {module_name} è¾“å‡º ===")
        logger.info(f"=== Module {module_name} output ===")
        # æ­£å¸¸åœæ­¢é€»è¾‘ï¼šæ£€æµ‹çº¦å®šé€€å‡ºç ï¼Œä¸è§¦å‘å¼‚å¸¸
        if result.stdout:
            logger.info(result.stdout)
        if result.stderr:
            logger.error(f"æ¨¡å— {module_name} é”™è¯¯è¾“å‡º: {result.stderr}")
            logger.error(f"Module {module_name} error output: {result.stderr}")

        logger.info(f"æ¨¡å— {module_name} é€€å‡ºä»£ç : {result.returncode}")
        logger.info(f"Module {module_name} exit code: {result.returncode}")

        # é‡è¯•é€»è¾‘
        #if result.returncode != 0 and retry_count < CONFIG["MAX_RETRIES"]:
            #retry_count += 1
            #logger.warning(f"æ¨¡å— {module_name} è¿è¡Œå¤±è´¥ï¼Œå°†è¿›è¡Œç¬¬ {retry_count}/{CONFIG['MAX_RETRIES']} æ¬¡é‡è¯•...")
            #return run_module(module_name, *args, retry_count=retry_count)

        return result.returncode

    except subprocess.TimeoutExpired:
        error_msg = f"æ¨¡å— {module_name} è¿è¡Œè¶…æ—¶ï¼ˆ{CONFIG['COMMAND_TIMEOUT']}ç§’ï¼‰"
        logger.error(error_msg)
        logger.error(f"Module {module_name} execution timeout ({CONFIG['COMMAND_TIMEOUT']} seconds)")
        raise ModuleRunnerError(error_msg) from None
    except subprocess.CalledProcessError as e:
        error_msg = f"æ¨¡å— {module_name} è¿è¡Œå¤±è´¥: {e.stderr}"
        logger.error(error_msg)
        logger.error(f"Module {module_name} execution failed: {e.stderr}")
        raise ModuleRunnerError(error_msg) from e
    except Exception as e:
        error_msg = f"æ¨¡å— {module_name} è¿è¡Œå¼‚å¸¸: {str(e)}"
        logger.error(error_msg, exc_info=True)
        logger.error(f"Module {module_name} runtime exception: {str(e)}", exc_info=True)
        raise ModuleRunnerError(error_msg) from e


def read_yaml_file(yaml_path: str) -> dict:
    """
    è¯»å–YAMLæ–‡ä»¶å¹¶è¿”å›å­—å…¸æ ¼å¼æ•°æ®

    Args:
        yaml_path: YAMLæ–‡ä»¶çš„è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰

    Returns:
        è§£æåçš„å­—å…¸æ•°æ®

    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        yaml.YAMLError: YAMLæ ¼å¼é”™è¯¯
        PermissionError: æ— æ–‡ä»¶è¯»å–æƒé™
    """
    # è½¬æ¢ä¸ºPathå¯¹è±¡ï¼Œæ–¹ä¾¿è·¯å¾„å¤„ç†
    file_path = Path(yaml_path)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file_path.exists():
        raise FileNotFoundError(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ â†’ {yaml_path}")

    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
    if not file_path.is_file():
        raise IsADirectoryError(f"é”™è¯¯ï¼š{yaml_path} æ˜¯ç›®å½•ï¼Œä¸æ˜¯æ–‡ä»¶")

    # è¯»å–å¹¶è§£æYAMLæ–‡ä»¶
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            # yaml.safe_load() é¿å…æ‰§è¡Œæ¶æ„ä»£ç ï¼Œæ›´å®‰å…¨
            data = yaml.safe_load(f)
        return data or {}
    except PermissionError:
        raise PermissionError(f"é”™è¯¯ï¼šæ— æƒé™è¯»å–æ–‡ä»¶ â†’ {yaml_path}")
    except yaml.YAMLError as e:
        raise yaml.YAMLError(f"é”™è¯¯ï¼šYAMLæ ¼å¼æ— æ•ˆ â†’ {e}")
    except Exception as e:
        raise Exception(f"æœªçŸ¥é”™è¯¯ï¼š{e}")

def merge_configs(config_path: str, setting_path: str) -> dict:
    """
    åˆå¹¶ç”¨æˆ·é…ç½®å’Œç³»ç»Ÿé…ç½®
    
    Args:
        config_path: ç”¨æˆ·é…ç½®æ–‡ä»¶è·¯å¾„
        setting_path: ç³»ç»Ÿé…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        åˆå¹¶åçš„é…ç½®å­—å…¸
    """
    # è¯»å–é…ç½®æ–‡ä»¶
    user_config = read_yaml_file(config_path)
    setting_config = read_yaml_file(setting_path)
    
    # åˆå¹¶é…ç½®
    merged = {}
    
    # è½¬æ¢ä¸ºæ¨¡å—é…ç½®
    #merged["modules"] = convert_to_module_config(user_config, setting_config)
    global_parameters = {}
    modules = {}
    project = user_config.get("project", {})
    profile = user_config.get("profile")

    rfdiffusion = user_config.get("rfdiffusion")
    mpnn = user_config.get("mpnn")
    mmseqs = user_config.get("mmseqs")
    esmfold = user_config.get("esmfold")
    alphafold2 = user_config.get("alphafold2")
    output_dir = project.get("output_dir", "./output")

    hmmer_setting = setting_config.get("hmmer", {})  # æ— "hmmer"åˆ™è¿”å›{}
    hmmer_args = hmmer_setting.get("args", {})  # æ— "args"åˆ™è¿”å›{}
    hmmer_user = profile or {}
    hmmer_args.update(hmmer_user)

    rfdiffusion_setting = setting_config.get("rfdiffusion", {})
    rfdiffusion_args = rfdiffusion_setting.get("args", {})
    rfdiffusion_user = rfdiffusion or {}
    rfdiffusion_args.update(rfdiffusion_user)

    mpnn_setting = setting_config.get("mpnn", {})
    mpnn_args = mpnn_setting.get("args", {})
    mpnn_user = mpnn or {}
    mpnn_args.update(mpnn_user)

    mmseqs_setting = setting_config.get("mmseqs", {})
    mmseqs_args = mmseqs_setting.get("args", {})
    mmseqs_user = mmseqs or {}
    mmseqs_args.update(mmseqs_user)


    esmfold_setting = setting_config.get("esmfold", {})
    esmfold_args = esmfold_setting.get("args", {})
    esmfold_user = esmfold or {}
    esmfold_args.update(esmfold_user)

    alphafold2_setting = setting_config.get("alphafold2", {})
    alphafold2_args = alphafold2_setting.get("args", {})
    alphafold2_user = alphafold2 or {}
    alphafold2_args.update(alphafold2_user)



    main_env = setting_config["environments"]["main_env"]

    protein_file = project.get("protein_file", '')
    proteinfile = os.path.basename(protein_file)
    protein_name = os.path.splitext(proteinfile)[0]
    os.makedirs(output_dir, exist_ok=True)
    if not os.path.isfile(protein_file):
        raise ValueError(f"è›‹ç™½è´¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š {protein_file}")
        raise ValueError(f"Protein file does not exist, please check the path: {protein_file}")
    if protein_file.endswith('.pdb'):
        input_pdb = f'{output_dir}/{protein_name}.pdb'
        print(f'è›‹ç™½è´¨æ–‡ä»¶æ˜¯pdbæ–‡ä»¶ï¼Œå°†è¯¥æ–‡ä»¶å¤åˆ¶åˆ°å·¥ä½œç›®å½•ä¸­ï¼š{input_pdb}')
        print(f'Protein file is in PDB format, copying to working directory: {input_pdb}')
        shutil.copy2(input_file, input_pdb)
    elif protein_file.endswith('.cif'):
        input_pdb = f'{output_dir}/{protein_name}.pdb'
        print(f'è›‹ç™½è´¨æ–‡ä»¶æ˜¯cifæ–‡ä»¶ï¼Œå°†è¯¥æ–‡ä»¶è½¬æ¢ä¸ºpdbæ–‡ä»¶ï¼Œä¿å­˜è·¯å¾„ä¸ºï¼š{input_pdb}\n')
        print(f'Protein file is in CIF format, converting to PDB format, save path: {input_pdb}\n')
        cif_to_pdb_biopython(
            cif_file_path=protein_file,
            pdb_file_path=input_pdb,
        )
    else:
        raise ValueError(f'è›‹ç™½è´¨æ–‡ä»¶ç±»å‹é”™è¯¯ï¼Œç›®å‰ä»…æ”¯æŒ.pdbå’Œ.cifæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶ï¼š{input_file}')
        raise ValueError(f'Incorrect protein file type, currently only .pdb and .cif files are supported, please check input file: {input_file}')



    # å…¨å±€å‚æ•°é…ç½® (profile)
    if project.get("anaconda_path") is not None:
        global_parameters['anaconda_path'] = project['anaconda_path']
    global_parameters['work_dir'] = output_dir
    merged['global parameters'] = global_parameters

    chain = project.get("chain", "A")

    log_config = {}

    # 1. è·å–å½“å‰è„šæœ¬çš„è·¯å¾„ï¼ˆå¯èƒ½æ˜¯ç›¸å¯¹è·¯å¾„ï¼‰
    script_path = __file__
    # 2. è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆé¿å…ç›¸å¯¹è·¯å¾„çš„æ­§ä¹‰ï¼‰
    absolute_script_path = os.path.abspath(script_path)
    # 3. æå–æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•è·¯å¾„
    script_dir_path = os.path.dirname(absolute_script_path)
    print(f'Segdesign.pyæ‰€åœ¨çš„ç›®å½•ï¼š{script_dir_path}\n')
    print(f'Directory where Segdesign.py is located: {script_dir_path}\n')

    # hmmer é…ç½® (profile)
    if profile is not None:
        hmmer_env = setting_config["environments"].get("hmmer", main_env)
        if hmmer_env is None:
            hmmer_env = main_env
        hmmer_output_folder = os.path.join(output_dir, hmmer_args.get("output_folder", "hmmer_out"))
        hmmer_bitscore = hmmer_args.get("bitscore", 0.3)
        hmmer_n_iter = hmmer_args.get("n_iter", 5)
        hmmer_database = hmmer_args.get("database", "")
        hmmer_cpu = hmmer_args.get("cpu", 10)
        hmmer_minimum_sequence_coverage = hmmer_args.get("minimum_sequence_coverage", 50)
        hmmer_minimum_column_coverage = hmmer_args.get("minimum_column_coverage", 70)
        identity = hmmer_args.get("identity", 0.3)
        modules["hmmer"] = {
            "env_name": hmmer_env,
            "args": {
                "input_file": input_pdb,
                "select_chain": chain,
                "output_folder": hmmer_output_folder,
                "bitscore": hmmer_bitscore,
                "n_iter": hmmer_n_iter,
                "database": hmmer_database,
                "cpu": hmmer_cpu,
                "minimum_sequence_coverage": hmmer_minimum_sequence_coverage,
                "minimum_column_coverage": hmmer_minimum_column_coverage,
                "identity": identity,
                "final_report_folder": output_dir,  # æ–°å¢ï¼šæœ€ç»ˆæŠ¥å‘Šè¾“å‡ºåˆ°æ€»å·¥ä½œç›®å½•
            }
        }

        log_config['hmmer'] = " 2>&1 | tee " + os.path.join(hmmer_output_folder,'hmmer_out.log')


    if project.get("segment") is not None:

        # rfdiffusion é…ç½®
        if rfdiffusion is not None:

            run_inference_path = rfdiffusion_args["run_inference_path"]
            print(f'æ­£åœ¨æ£€æµ‹ run_inference.py çš„è·¯å¾„æ˜¯å¦æ­£ç¡®... ')
            print(f'Checking if run_inference.py path is correct... ')
            if not os.path.isfile(run_inference_path):
                if not os.path.isabs(run_inference_path):
                    run_inference_path = os.path.join(script_dir_path, run_inference_path)
                    if os.path.isfile(run_inference_path):
                        print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                        print(f'Check completed, path is correct\n')
                    else:
                        raise ValueError(f'run_inference_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{run_inference_path}')
                        raise ValueError(f'run_inference_path path is incorrect, please check: {run_inference_path}')
                else:
                    raise ValueError(f'run_inference_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{run_inference_path}')
                    raise ValueError(f'run_inference_path path is incorrect, please check: {run_inference_path}')
            else:
               print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
               print(f'Check completed, path is correct\n')

            rfdiffusion_output_folder = os.path.join(output_dir, rfdiffusion_args.get("output_folder", "rfdiffusion_out"))
            output_prefix = os.path.join(rfdiffusion_output_folder, f"sample/{protein_name}_{chain}")
            num_designs = rfdiffusion_args.get("num_designs", 10)
            contigs = f"[{chain}1-{project.get('sequence_length', '')}]"
            inpaint_str = f"[{chain}{project.get('segment', '')}]"
            partial_T = rfdiffusion_args["diffuser.partial_T"]
            rfdiffusion_env = setting_config["environments"]["rfdiffusion"]

            modules["rfdiffusion"] = {
                "env_name": rfdiffusion_env,
                "args": {
                    "run_inference_path": run_inference_path,
                    "inference.input_pdb": input_pdb,
                    "inference.output_prefix": output_prefix,
                    "inference.num_designs": num_designs,
                    "contigmap.contigs": contigs,
                    "contigmap.inpaint_str": inpaint_str,
                    "diffuser.partial_T": partial_T,
                }
            }
            if rfdiffusion_args.get("contigmap.inpaint_seq") is not None:
                modules["rfdiffusion"]["args"]["contigmap.inpaint_seq"] = rfdiffusion_args.get("contigmap.inpaint_seq")

            # RFdiffusion_report é…ç½®
            rfdiffusion_report_env = setting_config["environments"].get("rfdiffusion_report", main_env)
            if rfdiffusion_report_env is None:
                rfdiffusion_report_env = main_env
            rfdiffusion_threshold = rfdiffusion_args.get("threshold", 0.6)
            modules["rfdiffusion_report"] = {
                "env_name": rfdiffusion_report_env,
                "args": {
                    "input_pdb": input_pdb,
                    "rfdiffusion_prefix": output_prefix,
                    "inpaint_str": inpaint_str,
                    "threshold": rfdiffusion_threshold,
                    "final_report_folder": output_dir,  # æ–°å¢ï¼šæœ€ç»ˆæŠ¥å‘Šè¾“å‡ºåˆ°æ€»å·¥ä½œç›®å½•
                }

            }

            # æ·»åŠ ç»“æ„çº¦æŸ
            select_helix = rfdiffusion_args.get("helix")
            select_strand = rfdiffusion_args.get("strand")
            if select_helix and select_strand is not True:
                modules["rfdiffusion"]["args"]["contigmap.inpaint_str_helix"] = \
                    f"[{chain}{project.get('segment', '')}]"
                modules["rfdiffusion_report"]["args"]['ss'] = f"helix"
            elif select_strand and select_helix is not True:
                modules["rfdiffusion"]["args"]["contigmap.inpaint_str_strand"] = \
                    f"[{chain}{project.get('segment', '')}]"
                modules["rfdiffusion_report"]["args"]['ss'] = "strand"
            else:
                raise ModuleRunnerError(
                    f"Abnormal setting of secondary structure in the design area of module rfdiffusion")

            log_config['rfdiffusion'] = " 2>&1 | tee "  + os.path.join(rfdiffusion_output_folder, 'rfdiffusion_out.log')
            log_config['rfdiffusion_report'] = " 2>&1 | tee -a " + os.path.join(rfdiffusion_output_folder, 'rfdiffusion_out.log')



        # mpnn é…ç½®
        if mpnn is not None:
            mpnn_env = setting_config["environments"]["mpnn"]

            parse_multiple_chains_path = mpnn_args["parse_multiple_chains_path"]
            assign_fixed_chains_path = mpnn_args["assign_fixed_chains_path"]
            make_fixed_positions_dict_path = mpnn_args["make_fixed_positions_dict_path"]
            protein_mpnn_run_path = mpnn_args["protein_mpnn_run_path"]


            print(f'æ­£åœ¨æ£€æµ‹ parse_multiple_chains_path çš„è·¯å¾„æ˜¯å¦æ­£ç¡®... ')
            print(f'Checking if parse_multiple_chains_path path is correct... ')
            if not os.path.isfile(parse_multiple_chains_path):
                if not os.path.isabs(parse_multiple_chains_path):
                    parse_multiple_chains_path = os.path.join(script_dir_path, parse_multiple_chains_path)
                    if os.path.isfile(parse_multiple_chains_path):
                        print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                        print(f'Check completed, path is correct\n')
                    else:
                        raise ValueError(f'parse_multiple_chains_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{parse_multiple_chains_path}')
                        raise ValueError(f'parse_multiple_chains_path path is incorrect, please check: {parse_multiple_chains_path}')
                else:
                    raise ValueError(f'parse_multiple_chains_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{parse_multiple_chains_path}')
                    raise ValueError(f'parse_multiple_chains_path path is incorrect, please check: {parse_multiple_chains_path}')
            else:
                print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                print(f'Check completed, path is correct\n')

            print(f'æ­£åœ¨æ£€æµ‹ assign_fixed_chains_path çš„è·¯å¾„æ˜¯å¦æ­£ç¡®... ')
            print(f'Checking if assign_fixed_chains_path path is correct... ')
            if not os.path.isfile(assign_fixed_chains_path):
                if not os.path.isabs(assign_fixed_chains_path):
                    assign_fixed_chains_path = os.path.join(script_dir_path, assign_fixed_chains_path)
                    if os.path.isfile(assign_fixed_chains_path):
                        print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                        print(f'Check completed, path is correct\n')
                    else:
                        raise ValueError(f'assign_fixed_chains_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{assign_fixed_chains_path}')
                        raise ValueError(f'assign_fixed_chains_path path is incorrect, please check: {assign_fixed_chains_path}')
                else:
                    raise ValueError(f'assign_fixed_chains_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{assign_fixed_chains_path}')
                    raise ValueError(f'assign_fixed_chains_path path is incorrect, please check: {assign_fixed_chains_path}')
            else:
                print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                print(f'Check completed, path is correct\n')

            print(f'æ­£åœ¨æ£€æµ‹ make_fixed_positions_dict_path çš„è·¯å¾„æ˜¯å¦æ­£ç¡®... ')
            print(f'Checking if make_fixed_positions_dict_path path is correct... ')
            if not os.path.isfile(make_fixed_positions_dict_path):
                if not os.path.isabs(make_fixed_positions_dict_path):
                    make_fixed_positions_dict_path = os.path.join(script_dir_path, make_fixed_positions_dict_path)
                    if os.path.isfile(make_fixed_positions_dict_path):
                        print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                        print(f'Check completed, path is correct\n')
                    else:
                        raise ValueError(f'make_fixed_positions_dict_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{make_fixed_positions_dict_path}')
                        raise ValueError(f'make_fixed_positions_dict_path path is incorrect, please check: {make_fixed_positions_dict_path}')
                else:
                    raise ValueError(f'make_fixed_positions_dict_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{make_fixed_positions_dict_path}')
                    raise ValueError(f'make_fixed_positions_dict_path path is incorrect, please check: {make_fixed_positions_dict_path}')
            else:
                print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                print(f'Check completed, path is correct\n')

            print(f'æ­£åœ¨æ£€æµ‹ protein_mpnn_run_path çš„è·¯å¾„æ˜¯å¦æ­£ç¡®... ')
            print(f'Checking if protein_mpnn_run_path path is correct... ')
            if not os.path.isfile(protein_mpnn_run_path):
                if not os.path.isabs(protein_mpnn_run_path):
                    protein_mpnn_run_path = os.path.join(script_dir_path, protein_mpnn_run_path)
                    if os.path.isfile(protein_mpnn_run_path):
                        print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                        print(f'Check completed, path is correct\n')
                    else:
                        raise ValueError(f'protein_mpnn_run_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{protein_mpnn_run_path}')
                        raise ValueError(f'protein_mpnn_run_path path is incorrect, please check: {protein_mpnn_run_path}')
                else:
                    raise ValueError(f'protein_mpnn_run_pathè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š{protein_mpnn_run_path}')
                    raise ValueError(f'protein_mpnn_run_path path is incorrect, please check: {protein_mpnn_run_path}')
            else:
                print(f'æ£€æµ‹å®Œæ¯•ï¼Œè·¯å¾„æ­£ç¡®\n')
                print(f'Check completed, path is correct\n')


            if mpnn_args.get("pdb_folder") is not None:
                pdb_foler = mpnn_args.get("pdb_folder")
            else:
                pdb_foler = os.path.join(output_dir, f"rfdiffusion_out/filter_results")
            mpnn_output_folder = os.path.join(output_dir, mpnn_args.get("output_folder","mpnn_out"))
            chain_list = chain
            position_list =  f"{chain}{project.get('segment', '')}"
            num_seq_per_target = mpnn_args.get("num_seq_per_target", 20)
            sampling_temp = mpnn_args.get("sampling_temp", 0.3)
            seed = mpnn_args.get("seed", 42)
            batch_size = mpnn_args.get("batch_size", 1)

            modules["mpnn"] = {
                "env_name": mpnn_env,
                "args": {
                    "parse_multiple_chains_path": parse_multiple_chains_path,
                    "assign_fixed_chains_path": assign_fixed_chains_path,
                    "make_fixed_positions_dict_path": make_fixed_positions_dict_path,
                    "protein_mpnn_run_path": protein_mpnn_run_path,
                    "pdb_folder": pdb_foler,
                    "output_folder": mpnn_output_folder,
                    "chain_list": chain_list,
                    "position_list": position_list,
                    "num_seq_per_target": num_seq_per_target,
                    "sampling_temp": sampling_temp,
                    "seed": seed,
                    'batch_size': batch_size,
                    #"top_percent": int(proteinmpnn.get("threshold", 0.9))
                }
            }

            # mpnn_report é…ç½®
            mpnn_report_env = setting_config["environments"].get("mpnn_report", main_env)
            if mpnn_report_env is None:
                mpnn_report_env = main_env
            seq_folder = os.path.join(mpnn_output_folder, "seqs")
            mpnn_report_output_folder = mpnn_output_folder
            top_percent = mpnn_args.get("top_percent", 0.5)
            rfdiffusion_report_path = mpnn_args.get("rfdiffusion_report_path")

            modules["mpnn_report"] = {
                "env_name": mpnn_report_env,
                "args": {
                    "seq_folder": seq_folder,
                    "output_folder": mpnn_report_output_folder,
                    "top_percent": top_percent,
                    "generate_report": True,  # æ·»åŠ ç”ŸæˆæŠ¥å‘Šæ ‡å¿—
                    "final_report_folder": output_dir,  # æ–°å¢ï¼šæœ€ç»ˆæŠ¥å‘Šè¾“å‡ºåˆ°æ€»å·¥ä½œç›®å½•
                    "rfdiffusion_report_path": rfdiffusion_report_path,
                    "position_list": position_list,
                    'protein_pdb': input_pdb

                }
            }
            log_config['mpnn'] = " 2>&1 | tee " + os.path.join(mpnn_report_output_folder, 'mpnn_out.log')
            log_config['mpnn_report'] = " 2>&1 | tee -a " + os.path.join(mpnn_report_output_folder, 'mpnn_out.log')



        # èšç±»åˆ†æé…ç½®
        if mmseqs is not None:
            mmseqs_env = setting_config["environments"].get("mmseqs", main_env)
            if mmseqs_env is None:
                mmseqs_env = main_env
            if mmseqs_args.get("input_folder") is not None:
                mmseqs_input_folder = mmseqs_args.get("input_folder")
            else:
                if mpnn is not None:
                    mmseqs_input_folder = os.path.join(mpnn_report_output_folder, 'top_filter')
                else:
                    mmseqs_input_folder =os.path.join(output_dir, 'mpnn_out', 'top_filter')

            mmseqs_output_folder = os.path.join(output_dir, mmseqs_args.get("output_folder", "mmseqs_out"))
            threads = mmseqs_args.get("threads", 8)
            min_seq_id = mmseqs_args.get("min_seq_id")
            cov_mode = mmseqs_args.get("cov_mode", 0)
            coverage = mmseqs_args.get("c", mmseqs_args.get("coverage", 0.8))
            mmseqs_path = mmseqs_args.get("mmseqs_path")
            sensitivity = mmseqs_args.get("s", mmseqs_args.get("sensitivity", 4.0))
            position_list = f"{chain}{project.get('segment', '')}"

            modules["mmseqs"] = {
                "env_name": mmseqs_env,
                "args": {
                    'input_folder': mmseqs_input_folder,
                    "output_folder": mmseqs_output_folder,
                    "position_list": position_list,
                    "threads": threads,
                    "min_seq_id": min_seq_id,
                    "cov_mode": cov_mode,
                    "coverage": coverage,
                    "mmseqs_path": mmseqs_path,
                    "sensitivity": sensitivity,
                }
            }

            log_config['mmseqs'] = " 2>&1 | tee " + os.path.join(mmseqs_output_folder, 'mmseqs_out.log')

            '''
            modules["mpnn_report"] = {
                "env_name": mpnn_report_env,
                "args": {
                    "seq_folder": seq_folder,
                    "output_folder": mpnn_report_output_folder,
                    "top_percent": top_percent,
                    "position_list": position_list,
                    "threads": threads,
                    "min_seq_id": min_seq_id,
                    "cov_mode": cov_mode,
                    "coverage": coverage,
                    "mmseqs_path": mmseqs_path,
                    "sensitivity": sensitivity,

                }
            }
            '''

        # esmfold é…ç½®
        if esmfold is not None:
            esmfold_env = setting_config["environments"]["esmfold"]
            if esmfold_args.get("input_folder") is not None:
                esmfold_input_folder = esmfold_args.get("input_folder")
            else:
                esmfold_input_folder = os.path.join(output_dir, f"mmseqs_out/results")
            esmfold_output_folder = os.path.join(output_dir, esmfold_args.get("output_folder","esmfold_out"))
            mmseqs_report_path = os.path.join(output_dir, "mmseqs_report.csv")


            modules["esmfold"] = {
                "env_name": esmfold_env,
                "args": {
                    "input_folder": esmfold_input_folder,
                    "output_folder": esmfold_output_folder,
                    "mmseqs_report_path": mmseqs_report_path,
                }
            }

            # esmfold_report é…ç½®
            esmfold_report_env = setting_config["environments"].get("esmfold_report", main_env)
            if esmfold_report_env is None:
                esmfold_report_env = main_env
            fasta_folder = esmfold_input_folder
            esmfold_folder = esmfold_output_folder
            plddt_threshold = esmfold_args.get("plddt_threshold")
            ptm_threshold = esmfold_args.get("ptm_threshold")
            if esmfold_args.get("original_protein_chain_path") is not None:
                original_protein_chain_path = esmfold_args.get("original_protein_chain_path")
            else:
                chain_folder = os.path.join(output_dir, f"hmmer_out/target_chain_pdb")
                filenames = f"{protein_name}_{chain}.pdb"
                original_protein_chain_path = os.path.join(chain_folder, filenames)

            if esmfold_args.get("seq_range_str") is not None:
                seq_range_str = esmfold_args.get("seq_range_str")
            else:
                seq_range_str = project.get("segment")

            esmfold_ss = esmfold_args.get("ss")
            if esmfold_ss is not None:
                ss_threshold = esmfold_args.get("ss_threshold")
                if ss_threshold is not None:
                    pass
                else:
                    ss_threshold = rfdiffusion_args.get("threshold", 0.6)
                modules["esmfold_report"] = {
                    "env_name": esmfold_report_env,
                    "args": {
                        "esmfold_folder": esmfold_folder,
                        "original_protein_chain_path": original_protein_chain_path,
                        "seq_range_str": seq_range_str,
                        'ss': esmfold_ss,
                        'ss_threshold': ss_threshold,
                    }
                }
            else:
                if rfdiffusion is not None:
                    esmfold_ss = modules["rfdiffusion_report"]["args"]['ss']
                    ss_threshold = rfdiffusion_threshold
                    modules["esmfold_report"] = {
                        "env_name": esmfold_report_env,
                        "args": {
                            "esmfold_folder": esmfold_folder,
                            "original_protein_chain_path": original_protein_chain_path,
                            "seq_range_str": seq_range_str,
                            'ss': esmfold_ss,
                            'ss_threshold': ss_threshold,
                        }
                    }
                else:
                    modules["esmfold_report"] = {
                        "env_name": esmfold_report_env,
                        "args": {
                            "esmfold_folder": esmfold_folder,
                            "original_protein_chain_path": original_protein_chain_path,
                            "seq_range_str": seq_range_str,
                        }
                    }
                if ptm_threshold is not None:
                    modules['esmfold_report']['args']['ptm_threshold'] = ptm_threshold
                if plddt_threshold is not None:
                    modules['esmfold_report']['args']['plddt_threshold'] = plddt_threshold

            esmfold_ss_filter = esmfold_args.get("ss_filter", True)
            if esmfold_ss_filter is None:
                esmfold_ss_filter = True
            modules["esmfold_report"]["args"]["ss_filter"] = esmfold_ss_filter

            log_config['esmfold'] = " 2>&1 | tee " + os.path.join(esmfold_output_folder, 'esmfold_out.log')
            log_config['esmfold_report'] = " 2>&1 | tee -a " + os.path.join(esmfold_output_folder, 'esmfold_out.log')
        
        # alphafold2 é…ç½®
        if alphafold2 is not None:
            alphafold2_env = setting_config["environments"]["alphafold2"]
            if alphafold2_args.get("input_file") is not None:
                alphafold2_input_file = alphafold2_args.get("input_file")
            else:
                if esmfold is not None:
                    alphafold2_input_file = os.path.join(esmfold_output_folder, "filter_result.fa")
                else:
                    alphafold2_input_file = os.path.join(output_dir, "esmfold_out", "filter_result.fa")
            alphafold2_output_folder = os.path.join(output_dir, alphafold2_args.get("output_folder", "alphafold2_out"))
            esmfold_report_path = os.path.join(output_dir, "esmfold_report.csv")
            num_recycle = alphafold2_args.get("num_recycle", None)
            amber = alphafold2_args.get("amber", True)
            templates = alphafold2_args.get("templates", True)
            gpu = alphafold2_args.get("gpu", False)
            random_seed = alphafold2_args.get("random_seed", 0)

            modules["alphafold2"] = {
                "env_name": alphafold2_env,
                "args": {
                    "input_file": alphafold2_input_file,
                    "output_folder": alphafold2_output_folder,
                    "esmfold_report_path": esmfold_report_path,
                    "amber": amber,
                    "templates": templates,
                    'gpu': gpu,
                    'random_seed': random_seed,
                }
            }
            if num_recycle is not None:
                modules["alphafold2"]["args"]["num_recycle"] = num_recycle



            # alphafold2_report é…ç½®
            alphafold2_report_env = setting_config["environments"].get("alphafold2_report", main_env)
            if alphafold2_report_env is None:
                alphafold2_report_env = main_env
            #fasta_folder = esmfold_input_folder
            alphafold2_folder = alphafold2_output_folder
            af2_plddt_threshold = alphafold2_args.get("plddt_threshold")
            af2_ptm_threshold = alphafold2_args.get("ptm_threshold")
            esmfold_report_path = os.path.join(output_dir, "esmfold_report.csv")
            

            if alphafold2_args.get("seq_range_str") is not None:
                seq_range_str = alphafold2_args.get("seq_range_str")
            else:
                seq_range_str = project.get("segment")

            af2_ss = alphafold2_args.get("ss")
            if af2_ss is not None:
                af2_ss_threshold = alphafold2_args.get("ss_threshold")
                if af2_ss_threshold is not None:
                    pass
                else:
                    af2_ss_threshold = rfdiffusion_args.get("threshold", 0.6)
                modules["alphafold2_report"] = {
                    "env_name": alphafold2_report_env,
                    "args": {
                        "esmfold_report_path":esmfold_report_path,
                        'alphafold2_folder': alphafold2_folder,
                        "seq_range_str": seq_range_str,
                        'ss': af2_ss,
                        'ss_threshold': af2_ss_threshold,
                    }
                }
            else:
                if rfdiffusion is not None:
                    af2_ss = modules["rfdiffusion_report"]["args"]['ss']
                    af2_ss_threshold = rfdiffusion_threshold
                    modules["alphafold2_report"] = {
                        "env_name": alphafold2_report_env,
                        "args": {
                            "esmfold_report_path":esmfold_report_path,
                            'alphafold2_folder': alphafold2_folder,
                            "seq_range_str": seq_range_str,
                            'ss': af2_ss,
                            'ss_threshold': af2_ss_threshold,
                        }
                    }
                else:
                    modules["alphafold2_report"] = {
                        "env_name": alphafold2_report_env,
                        "args": {
                            "esmfold_report_path":esmfold_report_path,
                            'alphafold2_folder': alphafold2_folder,
                            "seq_range_str": seq_range_str,
                        }
                    }

            if af2_ptm_threshold is not None:
                modules['alphafold2_report']['args']['ptm_threshold'] = af2_ptm_threshold
            if af2_plddt_threshold is not None:
                modules['alphafold2_report']['args']['plddt_threshold'] = af2_plddt_threshold
            af2_ss_filter = alphafold2_args.get("ss_filter", True)
            if af2_ss_filter is None:
                af2_ss_filter = True
            modules['alphafold2_report']['args']['ss_filter'] = af2_ss_filter

            log_config['alphafold2'] = " 2>&1 | tee " + os.path.join(alphafold2_output_folder, 'alphafold2_out.log')
            log_config['alphafold2_report'] = " 2>&1 | tee -a " + os.path.join(alphafold2_output_folder, 'alphafold2_out.log')

    # èšç±»åˆ†æé…ç½®
    """
        if project.get("segment") is not None and mmseqs is not None:
        # åŠ¨æ€è®¡ç®—Topç™¾åˆ†æ¯”æ–‡ä»¶å¤¹è·¯å¾„
        top_percent_value = mpnn_args.get("top_percent", 0.5)
        top_percent_str = f"{top_percent_value*100:.1f}%"
        
        # è·å–mpnn_output_folderï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
        mpnn_output_folder = os.path.join(output_dir, mpnn_args.get("output_folder", "mpnn_out"))
        top_sequences_folder = os.path.join(mpnn_output_folder, f"top_{top_percent_str}")
        
        # è§£æåŒºåŸŸä½ç½®
        position_range = project.get("segment", "")
        start_pos = int(position_range.split('-')[0]) if '-' in position_range else 1
        end_pos = int(position_range.split('-')[1]) if '-' in position_range else 100
        
        modules["cluster_analysis"] = {
            "env_name": setting_config["environments"].get("cluster_analysis", setting_config["environments"]["main_env"]),
            "args": {
                "input_folder": top_sequences_folder,
                "output_folder": os.path.join(output_dir, "cluster_analysis_out"),
                "start": start_pos,
                "end": end_pos,
                "min_seq_id": mmseqs_args.get("min_seq_id", 0.8),
                "cov_mode": mmseqs_args.get("cov_mode", 0),
                "coverage": mmseqs_args.get("coverage", 0.8),
                "mmseqs_path": mmseqs_args.get("mmseqs_path", "mmseqs"),
                "threads": mmseqs_args.get("threads", 8)
            }
        }

    """

    merged["modules"] = modules
    merged["log_config"] = log_config
    return merged


def global_work_dir_handling(yaml_data):
    """å¤„ç†å·¥ä½œç›®å½•"""
    work_dir = os.path.expanduser(yaml_data.get('global parameters', {}).get("work_dir", "./output"))
    if not os.path.exists(work_dir):
        os.makedirs(work_dir, exist_ok=True)
    return work_dir


def cif_to_pdb_biopython(cif_file_path, pdb_file_path):
    """
    ä½¿ç”¨Biopythonå°†CIFæ–‡ä»¶è½¬æ¢ä¸ºPDBæ–‡ä»¶
    :param cif_file_path: è¾“å…¥CIFæ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹/ç›¸å¯¹è·¯å¾„ï¼‰
    :param pdb_file_path: è¾“å‡ºPDBæ–‡ä»¶è·¯å¾„ï¼ˆç»å¯¹/ç›¸å¯¹è·¯å¾„ï¼‰
    """
    try:
        # 1. åˆå§‹åŒ–CIFè§£æå™¨ï¼ˆQUIET=Trueå…³é—­æ— å…³æ—¥å¿—è¾“å‡ºï¼‰
        cif_parser = MMCIFParser(QUIET=True)

        # 2. è§£æCIFæ–‡ä»¶ï¼Œè·å–ç»“æ„å¯¹è±¡ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°ä¸ºç»“æ„åç§°ï¼Œå¯è‡ªå®šä¹‰ï¼‰
        structure = cif_parser.get_structure("target_structure", cif_file_path)

        # 3. åˆå§‹åŒ–PDBå†™å…¥å™¨
        pdb_writer = PDBIO()

        # 4. è®¾ç½®è¦å†™å…¥çš„ç»“æ„å¯¹è±¡
        pdb_writer.set_structure(structure)

        # 5. å†™å…¥PDBæ–‡ä»¶ï¼ˆå¯é€‰ï¼šselectå‚æ•°ç­›é€‰åŸå­ï¼Œé»˜è®¤å†™å…¥å…¨éƒ¨åŸå­ï¼‰
        pdb_writer.save(pdb_file_path)

        print(f"è½¬æ¢æˆåŠŸï¼PDBæ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{pdb_file_path}")
        print(f"Conversion successful! PDB file saved to: {pdb_file_path}")

    except FileNotFoundError:
        raise ValueError(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°CIFæ–‡ä»¶ '{cif_file_path}'")
        raise ValueError(f"Error: CIF file not found '{cif_file_path}'")
    except Exception as e:
        print(f"è½¬æ¢å¤±è´¥ï¼š{str(e)}")
        print(f"Conversion failed: {str(e)}")
    return




if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="SegDesign: è›‹ç™½è´¨è®¾è®¡å·¥å…·",
        epilog="ç¤ºä¾‹ï¼špython Segdesign.py --config ./config/config.yaml --setting ./config/setting.yaml"
    )

    # æ·»åŠ å‚æ•°
    parser.add_argument(
        "--config",
        type=str,
        default=CONFIG["CONFIG_PATH"]["MAIN"],
        help="ç”¨æˆ·é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰"
    )
    parser.add_argument(
        "--setting",
        type=str,
        default=CONFIG["CONFIG_PATH"]["SETTING"],
        help="ç³»ç»Ÿé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰"
    )
    
    args = parser.parse_args()

    # åˆå¹¶é…ç½®
    merged_config = merge_configs(args.config, args.setting)
    print("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸï¼")
    print("âœ… Configuration files read successfully!")
    print("ğŸ“Š è§£æåçš„æ•°æ®ï¼š")
    print("ğŸ“Š Parsed data:")
    print(yaml.dump(merged_config, allow_unicode=True, sort_keys=False))

    # å¤„ç†å·¥ä½œç›®å½•
    output_dir = global_work_dir_handling(merged_config)

    log_path = os.path.join(output_dir, "Segdesign.log")
    logger = setup_logger(log_path)

    logger.info(f"å·¥ä½œç›®å½•: {output_dir}")
    logger.info(f"Working directory: {output_dir}")

    # å°†config.yamlå¤åˆ¶åˆ°å·¥ä½œç›®å½•ä¸‹

    shutil.copy(args.config, f"{output_dir}/config.yaml")

    # è·å–anacondaè·¯å¾„
    anaconda_path = merged_config["global parameters"].get("anaconda_path")

    # è¿è¡Œæ¨¡å—
    for module_name, params in merged_config["modules"].items():
        module_log_config = merged_config["log_config"][module_name]
        if module_name in CONFIG['MODULES']:
            try:
                logger.info(f"æ­£åœ¨è¿è¡Œæ¨¡å—: {module_name}")
                logger.info(f"Running module: {module_name}")
                run_module(
                    module_name=module_name,
                    anaconda_path=anaconda_path,
                    params=params,
                    module_log_config=module_log_config
                )
                logger.info(f"âœ… æ¨¡å— {module_name} è¿è¡ŒæˆåŠŸ")
                logger.info(f"âœ… Module {module_name} executed successfully")
            except ModuleRunnerError as e:
                logger.critical(f"âŒ æ¨¡å— {module_name} è¿è¡Œå¤±è´¥: {e}")
                logger.critical(f"âŒ Module {module_name} execution failed: {e}")
                exit(1)
            except KeyboardInterrupt:
                logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
                logger.info("Program interrupted by user")
                exit(0)
            except Exception as e:
                logger.critical(f"âŒ æ¨¡å— {module_name} æœªé¢„æœŸçš„é”™è¯¯: {str(e)}", exc_info=True)
                logger.critical(f"âŒ Module {module_name} unexpected error: {str(e)}", exc_info=True)
                exit(1)
    logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å—è¿è¡Œå®Œæˆï¼")
    logger.info("ğŸ‰ All modules completed!")


