import os
import re
#import biotite.structure.io as bsio
import torch
import esm
import argparse
import shutil
from datetime import datetime
#from esmfold_report import data_organization
import pandas as pd
import numpy as np
from typing import Dict

model = esm.pretrained.esmfold_v1()
model = model.eval().cuda()

def parse_args():
    parser = argparse.ArgumentParser(description='Protein 3D Structure Prediction(esmfold)', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--input_folder', type=str, help='Folder for storing sequence files')
    parser.add_argument('--output_folder', type=str, help='Folder for storing output files')
    parser.add_argument("--mmseqs_report_path", type=str, default=None,
                        help="The path to mmseqs_report.csv. If not entered, the default path will be used: {work_dir}/mmseqs_report.csv")
    

    return parser.parse_args()

#读取fasta文件中的序列，输出序列列表
def extract_sequences(file_path):
    #sequences = []
    dict_seq = {}
    with open(file_path, "r") as f:
        file_content = f.read()
    lines = file_content.strip().split('\n')
    i = 1
    while i < len(lines):
        index = lines[i-1].strip().strip('>')
        sequence = lines[i]
        #sequences.append(sequence)
        dict_seq[index] = sequence
        i += 2
    return dict_seq

#输入单序列，输出pdb字符串
def sequence_to_pdb(sequence):
    with torch.no_grad():
        output = model.infer(sequence)
    ptm = output['ptm'].item()
    #print('ptm:', ptm)
    plddt = np.mean(output['plddt'].cpu().numpy())
    #print('plddt:', plddt)
    # 3. 直接生成PDB格式的字符串
    pdb_string = model.output_to_pdb(output)[0]
    #print('pdb_string:', pdb_string)
    return pdb_string, ptm, plddt

#根据esmfold预测生成的文本生成pdb文件，可以被dssp识别
def generate_pdb_file(pdb_str,pdb_path,ptm,plddt):
    now = datetime.now()
    header = [
        f"HEADER    GENERATED BY ESMFOLD    pTM={ptm:.4g}    pLDDT={plddt:.4g}    {now:%d-%b-%y}"
    ]
    # 步骤1：将文本按换行符分割成行列表
    lines = pdb_str.split('\n')

    # 步骤2：过滤掉包含"PARENT"的行（列表推导式）
    filtered_lines = [line for line in lines if "PARENT" not in line]

    # 步骤3：将过滤后的行重新拼接成完整文本
    output_fix = '\n'.join(filtered_lines)

    with open(pdb_path, "w") as f:
        for line in header:
            f.write(line.ljust(80) + '\n')
        f.write(output_fix)
    return


#输入fasta文件，输出fasta文件中每条序列的预测结果（pdb文件）
def structure_prediction(file_path, output_folder):
    print('Now start structure prediction!')
    dict_seq = extract_sequences(file_path)
    print('file_path:', file_path)
    #print('file_path_sequence:', sequences)
    file_name = os.path.basename(file_path).rsplit('.')[0]
    folder = os.path.join(output_folder, file_name)
    print('folder:', folder)
    if not os.path.exists(folder):  ##新建文件夹
        os.makedirs(folder, exist_ok=True)

    ptm_l = []
    plddt_l = []
    seqs = []
    index_l = []
    for index, sequence in dict_seq.items():
        output, ptm, plddt = sequence_to_pdb(sequence)
        ptm_l.append(ptm)
        plddt_l.append(plddt)
        index_l.append(index)
        seqs.append(sequence)
        print(f'{file_path}')
        print(f'The structure of {index} has been generated.')
        out_path = os.path.join(output_folder, file_name, f'{index}.pdb')
        print('out_path:', out_path)
        generate_pdb_file(output, out_path, ptm, plddt)

    return index_l, seqs, ptm_l, plddt_l

#批量预测
def structure_prediction_filter_all(input_folder, output_pdb_folder, esmfold_report_path):
    files = os.listdir(input_folder)
    files = sorted(files, key=natural_sort_key)
    index_l = []
    seqs_l = []
    ptm_l = []
    plddt_l = []
    backbones  = []
    for file in files:
        file_path = os.path.join(input_folder, file)
        file_name = os.path.splitext(file)[0]
        index, seqs, ptm, plddt = structure_prediction(file_path, output_pdb_folder)
        index_l += index
        seqs_l += seqs
        ptm_l += ptm
        plddt_l += plddt
        backbone = [file_name]*len(index)
        backbones += backbone

    df = {
        'index': index_l,
        'backbone': backbones,
        'sequence': seqs_l,
        'esmfold_ptm': ptm_l,
        'esmfold_plddt': plddt_l
    }

    df_final = pd.DataFrame(df)
    df_final.to_csv(esmfold_report_path, index=False)

    return

def natural_sort_key(filename):
    """生成自然排序的key：将文件名拆分为字符串和数字部分，数字转整数"""
    parts = re.split(r'(\d+)', os.path.splitext(filename)[0])
    key = []
    for part in parts:
        if part.isdigit():
            key.append(int(part))
        else:
            key.append(part)
    return key

#读取mmseqs_report.csv文件，生成序列字典
def read_mmseqs_report(mmseqs_report_path: str) -> Dict[str, Dict[str, str]]:
    """
    读取mmseqs报告CSV文件，筛选whether_pass为True的行，按backbone分组构建嵌套字典

    输出字典结构示例：
    {
        "Dusp4_A_2": {
            "Dusp4_A_2_mpnn_0": "完整的sequence序列...",
            "Dusp4_A_2_mpnn_2": "完整的sequence序列...",
        },
        "Dusp4_A_8": {
            "Dusp4_A_8_mpnn_0": "完整的sequence序列...",
        }
    }

    Parameters:
        mmseqs_report_path: mmseqs报告的CSV文件路径（绝对/相对路径）

    Returns:
        嵌套字典：外层key为backbone值，内层key为index值，内层value为对应sequence序列
                 无符合条件数据时返回空字典

    Raises:
        FileNotFoundError: 指定的CSV文件不存在
        pd.errors.EmptyDataError: CSV文件为空
        pd.errors.ParserError: CSV文件格式错误，无法解析
        KeyError: CSV文件缺失必要列（backbone/whether_pass/index/sequence）
        TypeError: 输入的文件路径非字符串类型
    """
    # 1. 输入参数类型校验
    if not isinstance(mmseqs_report_path, str):
        raise TypeError(f"文件路径必须是字符串，当前类型：{type(mmseqs_report_path)}")
    if not mmseqs_report_path.strip():
        raise ValueError("文件路径不能为空字符串")

    # 2. 读取CSV文件，捕获解析相关异常
    try:
        df = pd.read_csv(mmseqs_report_path)
    except FileNotFoundError:
        raise FileNotFoundError(f"未找到mmseqs报告文件：{mmseqs_report_path}")
    except pd.errors.EmptyDataError:
        raise pd.errors.EmptyDataError(f"mmseqs报告文件为空：{mmseqs_report_path}")
    except pd.errors.ParserError:
        raise pd.errors.ParserError(f"CSV格式错误，无法解析：{mmseqs_report_path}")

    # 3. 校验必要列是否存在
    required_cols = {"backbone", "whether_pass", "index", "sequence"}
    missing_cols = required_cols - set(df.columns)
    if missing_cols:
        raise KeyError(f"CSV文件缺失必要列，缺失列：{', '.join(missing_cols)}")

    # 4. 筛选whether_pass为True的行（兼容布尔/字符串/数值类型，提升鲁棒性）
    filtered_df = df.copy()
    # 把所有'-'替换为False，再统一转布尔筛选
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('-', False)
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('False', False)
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('True', True)
    filtered_df = filtered_df[filtered_df['whether_pass'].astype(bool)]
    #print('filtered_df:', filtered_df)
    # 无符合条件数据时直接返回空字典
    if filtered_df.empty:
        return {}

    # 5. 构建结果字典（保持backbone的原始出现顺序，drop_duplicates比unique更直观）
    result_dict = {}
    # 按原始顺序获取唯一的backbone值
    unique_backbones = filtered_df["backbone"].drop_duplicates().tolist()
    for backbone in unique_backbones:
        # 筛选当前backbone的所有数据
        backbone_subdf = filtered_df[filtered_df["backbone"] == backbone]
        # 构建内层字典：index -> sequence
        inner_dict = {row["index"]: row["sequence"] for _, row in backbone_subdf.iterrows()}
        result_dict[backbone] = inner_dict

    return result_dict


def mmseqs_report_to_structure_prediction(mmseqs_report_path, output_pdb_folder):
    ptm_l = []
    plddt_l = []
    result_dict = read_mmseqs_report(mmseqs_report_path)
    print('Now start structure prediction!')
    for backbone, value in result_dict.items():
        backbone_folder = os.path.join(output_pdb_folder, backbone)
        if not os.path.exists(backbone_folder):
            os.makedirs(backbone_folder, exist_ok=True)
        for index, seq in value.items():
            output, ptm , plddt = sequence_to_pdb(seq)
            ptm_l.append(ptm)
            plddt_l.append(plddt)
            pdb_path = f'{backbone_folder}/{index}.pdb'
            print(f'{pdb_path}')
            print(f'The structure of sequence {index} has been generated.')
            generate_pdb_file(
                pdb_str=output,
                pdb_path=pdb_path,
                ptm = ptm,
                plddt=plddt,
            )
    return ptm_l, plddt_l

def esmfold_report_csv(mmseqs_report_path, esmfold_report_path, ptm_l, plddt_l):
    df_original = pd.read_csv(mmseqs_report_path)
    #  根据whether_pass列筛选出为TRUE的行

    filtered_df = df_original.copy()
    # 把所有'-'替换为False，再统一转布尔筛选
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('-', True)
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('False', False)
    filtered_df['whether_pass'] = filtered_df['whether_pass'].replace('True', True)
    df_filtered = filtered_df[filtered_df['whether_pass'].astype(bool)]

    #df_filtered = df_original[df_original['whether_pass'] == True].copy()
    df_filtered = df_filtered.drop(columns=['whether_pass'], axis=1)
    df_renamed = df_filtered.rename(
        columns={
            'ss8': 'rfdiffusion_ss8',  # 旧列名→新列名
            'ss3': 'rfdiffusion_ss3',
            'H_prop': 'rfdiffusion_H_prop',
            'E_prop': 'rfdiffusion_E_prop',
            'C_prop': 'rfdiffusion_C_prop',
        }
    )
    #  在DataFrame最后添加新列
    df_final = df_renamed.copy()
    df_final['esmfold_ptm'] = ['-'] + ptm_l  # 新增ptm_score列
    df_final['esmfold_plddt'] = ['-'] + plddt_l  # 新增plddt_score列

    # 5. 保存为新的CSV文件
    df_final.to_csv(esmfold_report_path, index=False)
    return

def esmfold_report_csv_without_mmseqs_report():
    return



def main():
    args = parse_args()
    input_folder = os.path.expanduser(args.input_folder)
    output_folder = os.path.expanduser(args.output_folder)
    #plddt_threshold = args.plddt_threshold
    #seq_range_str = args.design_seq
    output_pdb_folder = os.path.join(output_folder, 'structure_prediction_files')
    #output_filter_folder = os.path.join(output_folder, 'filter_files')
    if not os.path.exists(output_pdb_folder):  ##新建文件夹
        os.makedirs(output_pdb_folder, exist_ok=True)

    #structure_prediction_filter_all(
        #input_folder=input_folder,
        #output_pdb_folder=output_pdb_folder
    #)

    if args.mmseqs_report_path is not None:
        mmseqs_report_path = args.mmseqs_report_path
    else:
        work_dir = output_folder.rsplit('/',1)[0]
        mmseqs_report_path = os.path.join(work_dir, 'mmseqs_report.csv')
    
    if not os.path.exists(mmseqs_report_path):
        print("未检测到mmseqs_report.csv，将使用FASTA文件中的序列信息")
        print("mmseqs_report.csv not detected, will use sequence information from FASTA file")
    else:
        print(f"检测到mmseqs_report.csv，路径: {mmseqs_report_path}")
        print(f"Detected mmseqs_report.csv, path: {mmseqs_report_path}")



    work_dir = output_folder.rsplit('/', 1)[0]
    esmfold_report_path = os.path.join(work_dir, 'esmfold_report.csv')
    if os.path.exists(mmseqs_report_path):
        ptm_l, plddt_l = mmseqs_report_to_structure_prediction(mmseqs_report_path, output_pdb_folder)
        esmfold_report_csv(mmseqs_report_path, esmfold_report_path, ptm_l, plddt_l)
    else:
        structure_prediction_filter_all(
            input_folder=input_folder,
            output_pdb_folder=output_pdb_folder,
            esmfold_report_path=esmfold_report_path
        )






if __name__ == '__main__':
    main()